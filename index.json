[{"uri":"https://quangbom16.github.io/full-workshop/4-eventparticipated/4.1-event1/","title":"Event: AI/ML/GenAI on AWS Workshop","tags":[],"description":"","content":"Summary Report: \u0026ldquo;AI/ML/GenAI on AWS Workshop\u0026rdquo; Event Objectives Provide a comprehensive overview of the AI/ML landscape specifically within the Vietnam market. Deep dive into Amazon SageMaker for end-to-end machine learning lifecycle management. Explore advanced Generative AI capabilities using Amazon Bedrock. Master modern techniques like RAG (Retrieval-Augmented Generation) and Prompt Engineering. Enable hands-on learning through live demos of SageMaker Studio and building GenAI chatbots. Speakers Kha Van – AWS Community Leader and Workshop Host Key Highlights Understanding the AI/ML Landscape in Vietnam Overview of the current state of AI adoption in Vietnam. Networking and ice-breaking activities to connect with local peers. Discussion on local market trends, opportunities, and challenges for AI implementation. Amazon SageMaker – End-to-End ML Platform Data Preparation and Labeling\nStrategies for efficient data collection. Tools for labeling datasets to prepare for supervised learning. Preprocessing workflows to ensure data quality. Model Training, Tuning, and Deployment\nUtilizing built-in algorithms vs. custom scripts. Hyperparameter tuning to optimize model performance. Deployment strategies for production environments. Integrated MLOps Capabilities\nImplementing CI/CD for Machine Learning. Automating pipelines to reduce manual intervention. Monitoring model performance in production. Live Demo: SageMaker Studio Walkthrough\nNavigating the unified IDE for ML development. Visualizing the end-to-end workflow from data to deployment. Generative AI with Amazon Bedrock Foundation Models (FMs)\nComparison and selection guide for top models: Claude, Llama, and Titan. Understanding the trade-offs between performance, cost, and latency. Prompt Engineering Techniques\nBest practices for interacting with LLMs. Advanced techniques: Chain-of-Thought (CoT) reasoning and Few-shot learning to improve model accuracy. Retrieval-Augmented Generation (RAG)\nArchitecture deep dive: Connecting LLMs with external data sources. Integration with Knowledge Bases to reduce hallucinations and provide up-to-date information. Bedrock Agents \u0026amp; Guardrails\nAgents: Creating multi-step workflows and integrating with external tools/APIs to perform tasks. Guardrails: Implementing safety filters and content moderation to ensure responsible AI usage. Live Demo: Building a Generative AI Chatbot\nStep-by-step guide to building a functional chatbot using Amazon Bedrock. Key Takeaways ML \u0026amp; GenAI Strategy Model Selection Matters: Choosing the right Foundation Model (Claude vs. Llama vs. Titan) depends heavily on the specific use case and budget. RAG is Essential: For enterprise applications, RAG is crucial to provide context-aware and accurate responses based on proprietary data. Safety First: Implementing Guardrails is non-negotiable for production GenAI applications to prevent harmful output. Technical Architecture SageMaker as the Hub: Serves as the central nervous system for traditional ML models (Predictive AI). Bedrock as the GenAI Layer: Provides a serverless, API-based abstraction to access powerful FMs without managing infrastructure. Agents for Action: Moving beyond simple text generation to executing tasks (API calls, data lookups) using Bedrock Agents. Operational Excellence Prompt Engineering as a Skill: It is a critical capability for developers to extract the best performance from LLMs. MLOps: Continuous integration and deployment are vital for maintaining model relevance and performance over time. Applying to Work Implement RAG: Build internal knowledge search tools using Amazon Bedrock and Knowledge Bases to help employees find information faster. Develop Smart Agents: Use Bedrock Agents to automate customer service tasks or internal workflows. Standardize ML Workflows: Migrate ad-hoc ML experiments to Amazon SageMaker pipelines for better governance and reproducibility. Adopt Guardrails: Review current GenAI applications and apply Bedrock Guardrails to ensure compliance and safety. Optimize Costs: Evaluate the usage of different Foundation Models to balance between capability and cost. Event Experience Attending the \u0026ldquo;AI/ML/GenAI on AWS Workshop\u0026rdquo; was a highly practical and forward-looking experience. The session effectively bridged the gap between traditional Machine Learning and the cutting-edge world of Generative AI. Key experiences included:\nThe SageMaker Studio walkthrough clarified how to manage the complex lifecycle of ML models in a single interface. The deep dive into Amazon Bedrock was particularly valuable, especially the comparison between models like Claude and Llama, which helped clarify when to use which model. Learning about Retrieval-Augmented Generation (RAG) changed my perspective on how to make LLMs useful for business-specific data without retraining models. The session on Bedrock Agents opened up new possibilities for building applications that can actually do things, not just say things. Leveraging modern AI tools Explored Prompt Engineering techniques like Chain-of-Thought to improve reasoning in AI responses. Discovered how Guardrails can be configured to filter out inappropriate content automatically. Witnessed the speed of building a GenAI Chatbot live, demonstrating the rapid development cycle possible with AWS tools. Lessons learned Context is King: RAG is the most effective way to bring organizational knowledge into AI. Don\u0026rsquo;t reinvent the wheel: Use managed services like Bedrock instead of hosting your own LLMs unless absolutely necessary. Security \u0026amp; Safety: These should be designed into GenAI applications from day one using Guardrails, not added as an afterthought. Overall, the workshop provided a clear roadmap for adopting both predictive ML (SageMaker) and generative AI (Bedrock) within an organization, backed by relevant local context from the Vietnam market.\n"},{"uri":"https://quangbom16.github.io/full-workshop/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Multi-Platform File Analysis System - Clone VirusTotal Student Information: Full Name: Phạm Quang Nhật - SE194817\nUniversity: Ho Chi Minh City University of Technology and Education\nMajor: Information Assurance (IA)\nClass: AWS082025\nInternship Company : Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 09/12/2025\nReport Content Worklog Proposal Proposal document (.docx) Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Week 1: Getting familiar with AWS and basic AWS services\nWeek 2: Securing AWS Account, MFA \u0026amp; IAM Management\nWeek 3: VPC Networking, Security Groups \u0026amp; Site-to-Site VPN\nWeek 4: Project Ideation, Service Selection \u0026amp; Web Architecture\nWeek 5: Advanced EC2, Diagramming \u0026amp; Blog Translation\nWeek 6: Team Workflow, Backend Query Services \u0026amp; GitHub Pages\nWeek 7: Docker Containerization, Pricing \u0026amp; Preliminary Proposal\nWeek 8: Local Environment Config, Frontend Refinement \u0026amp; Dry Run\nWeek 9: UI Testing on AWS, DynamoDB \u0026amp; CloudFront\nWeek 10: Malware Hash Comparison Logic \u0026amp; CloudWatch\nWeek 11: DevOps Workshop (CI/CD), Testing \u0026amp; Networking\nWeek 12: Final Proposal, Slides \u0026amp; Security Best Practices\n"},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 09/08/2025 09/12/2025 https://policies.fcjuni.com/ 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 09/08/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 09/08/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 09/08/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 09/08/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ Week 1 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://quangbom16.github.io/full-workshop/3-blogstranslated/3.1-blog1/","title":"Tự động hóa báo cáo kiểm tra AWS Private CA và cảnh báo hết hạn chứng chỉ","tags":[],"description":"","content":"Bởi Santosh Vallurupalli và Manthan Raval\nBài viết gốc: Automating AWS Private CA audit reports and certificate expiration alerts – AWS Security Blog doc: GG docs Các tổ chức ngày nay phụ thuộc rất nhiều vào các kênh liên lạc an toàn và đáng tin cậy, và chứng chỉ kỹ thuật số đóng vai trò quan trọng trong việc bảo mật cơ sở hạ tầng nội bộ và bên ngoài bằng cách thiết lập lòng tin và cho phép giao tiếp được mã hóa. Trong khi chứng chỉ công khai thường được sử dụng để bảo mật các ứng dụng internet, nhiều tổ chức lại ưa thích chứng chỉ riêng tư cho các tài nguyên nội bộ để duy trì tính bảo mật và cho phép các cấu hình tùy chỉnh mà chứng chỉ công khai không hỗ trợ.\nAWS Private CA cung cấp một giải pháp toàn diện để tạo và quản lý hệ thống phân cấp chứng chỉ riêng tư trong cơ sở hạ tầng khóa công khai (PKI) của một tổ chức. AWS xử lý việc quản lý CA nặng nề, cho phép các tổ chức cấp chứng chỉ cho nhiều trường hợp sử dụng khác nhau, bao gồm tạo kênh liên lạc được mã hóa, xác thực máy khách và ký mã bằng mật mã.\nTuy nhiên, khi các khối lượng công việc phát triển — bao gồm các microservices gốc đám mây, môi trường container hóa và triển khai biên lai lai — các cấu hình chứng chỉ mặc định có thể không đáp ứng mọi nhu cầu. Ví dụ:\nChứng chỉ TLS riêng tư được yêu cầu bằng AWS Certificate Manager (ACM) đi kèm với thời gian hiệu lực cố định là 13 tháng. Các doanh nghiệp hiện đại có thể cần chứng chỉ tồn tại trong thời gian ngắn cho các container tạm thời hoặc chứng chỉ kéo dài cho hệ thống tại chỗ. Bạn có thể tạo và cập nhật chứng chỉ thông qua AWS CLI hoặc AWS SDK. Tuy nhiên, ACM không tự theo dõi việc hết hạn của các chứng chỉ được cấp bằng API acm-pca:IssueCertificate và không được yêu cầu bằng ACM. Việc thiếu giám sát này có thể dẫn đến gián đoạn hoạt động.\nTrong bài đăng này, chúng tôi sẽ hướng dẫn bạn quy trình tự động hóa tùy chỉnh tận dụng các báo cáo kiểm tra của AWS Private CA để chủ động giám sát việc hết hạn chứng chỉ bằng cách sử dụng Amazon EventBridge, AWS Lambda, Amazon S3, Amazon SNS và AWS Security Hub.\nThách thức: Quản lý chứng chỉ ngoài các cài đặt mặc định Các chứng chỉ được yêu cầu bằng ACM được cấp bởi CA riêng của bạn thông qua console mặc định có thời gian hiệu lực là 13 tháng. ACM theo dõi và tự động gia hạn chúng. Tuy nhiên, môi trường IT hiện đại có các yêu cầu đa dạng:\nChứng chỉ tồn tại trong thời gian ngắn: Các môi trường container hóa (EKS, ECS) hoặc Service Mesh (Istio, Linkerd) thường dùng chứng chỉ có hiệu lực vài giờ hoặc vài ngày để giảm bề mặt tấn công. Chứng chỉ tồn tại lâu dài: Các hệ thống tại chỗ (on-premise), IoT hoặc môi trường hạn chế tài nguyên mạng có thể cần chứng chỉ nhiều năm để giảm gánh nặng quản trị. Khi sử dụng AWS CLI/SDK để cấp chứng chỉ tùy chỉnh mà không nhập vào ACM, các chứng chỉ này sẽ không được theo dõi, không kích hoạt CloudWatch Logs và không được gia hạn tự động. Nếu không có chế độ xem tập trung, bạn phải tự giám sát ngày hết hạn thủ công.\nĐiều kiện tiên quyết Để thực hiện hướng dẫn này, bạn cần có:\nMột tài khoản AWS. Một CA riêng từ AWS Private CA. Một chứng chỉ được tạo bên ngoài đã được nhập vào ACM (để thử nghiệm). Tổng quan giải pháp Giải pháp này sử dụng các dịch vụ AWS để giám sát trạng thái chứng chỉ, phát hiện các trường hợp hết hạn sắp tới và thông báo cho quản trị viên, đồng thời tích hợp vào Security Hub.\nKiến trúc:\nEventBridge Rule (PCAReportRule): Kích hoạt theo lịch trình (ví dụ: hàng ngày). Lambda 1 (PCAauditReportLambdaGenerator): Gọi API để tạo báo cáo kiểm tra (audit report) và lưu vào S3. S3 Bucket: Lưu trữ báo cáo dưới dạng CSV. Lambda 2 (PCAAuditReportLambdaProcessor): Được kích hoạt bởi sự kiện S3:PutObject. Hàm này tải báo cáo, phân tích và tìm các chứng chỉ sắp hết hạn (ngưỡng mặc định 30 ngày). Amazon SNS: Gửi thông báo email cảnh báo. AWS Security Hub: Tạo các phát hiện (findings) để giám sát tập trung. Hình 1: Kiến trúc giải pháp\nTriển khai giải pháp 1. Triển khai mẫu CloudFormation Để bắt đầu, hãy tải xuống mẫu CloudFormation:\ncurl -O https://aws-security-blog-content.s3.us-east-1.amazonaws.com/public/sample/2526-monitor-private-ca-issued-certificates-aws-private-certificate-authority-eventbridge/ACM-PCA-Monitoring-cfn.yml Mẫu ACM-PCA-Monitoring-cfn.yml bao gồm các tham số tùy chỉnh như CertificateAuthorityArn, S3BucketName, CronJobExpression, SNSName, EmailAddress, và CertificateExpirationThreshold.\nChạy lệnh sau để tạo stack (thay thế các giá trị trong ngoặc \u0026lt;...\u0026gt; bằng thông tin của bạn):\naws cloudformation create-stack \\ --stack-name PCAMonitoringWorkflow \\ --template-body file://ACM-PCA-Monitoring-cfn.yml \\ --capabilities CAPABILITY_NAMED_IAM \\ --parameters \u0026#39;[ {\u0026#34;ParameterKey\u0026#34;: \u0026#34;CertificateAuthorityArn\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;\u0026lt;ARN_of_your_PrivateCA\u0026gt;\u0026#34;}, {\u0026#34;ParameterKey\u0026#34;: \u0026#34;S3BucketName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;\u0026lt;Name_of_s3_bucket\u0026gt;\u0026#34;}, {\u0026#34;ParameterKey\u0026#34;: \u0026#34;EventBridgeRuleName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;\u0026lt;Name_of_EventBridgeRule\u0026gt;\u0026#34;}, {\u0026#34;ParameterKey\u0026#34;: \u0026#34;CronJobExpression\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;cron(0 21 * * ? *)\u0026#34;}, {\u0026#34;ParameterKey\u0026#34;: \u0026#34;SNSName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;PCASNSTopic\u0026#34;}, {\u0026#34;ParameterKey\u0026#34;: \u0026#34;SQSName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;PCASQS\u0026#34;}, {\u0026#34;ParameterKey\u0026#34;: \u0026#34;EmailAddress\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;\u0026lt;Email_to_Receive_alerts\u0026gt;\u0026#34;}, {\u0026#34;ParameterKey\u0026#34;: \u0026#34;CertificateExpirationThreshold\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;30\u0026#34;} ]\u0026#39; Sau khi tạo stack, hãy kiểm tra email để xác nhận đăng ký SNS.\nHình 2: Email xác nhận đăng ký SNS\n2. Kiểm tra quy trình tự động hóa Tạo một chứng chỉ thử nghiệm có thời hạn ngắn (ví dụ: 20 ngày) để kích hoạt cảnh báo (vì ngưỡng mặc định là 30 ngày).\n# Generate a Private Key openssl genrsa -out private-key.pem 2048 # Generate a Certificate Signing Request (CSR) openssl req -new -key private-key.pem -out csr.pem -subj \u0026#34;/C=US/ST=Ohio/L=Columbus/O=MyOrg/OU=IT/CN=mydomain.com\u0026#34; # Issue a Certificate (valid for 20 days) aws acm-pca issue-certificate \\ --certificate-authority-arn \u0026lt;specify_arn_of_PrivateCA\u0026gt; \\ --csr \u0026#34;$(cat csr.pem | base64 | tr -d \u0026#39;\\n\u0026#39;)\u0026#34; \\ --signing-algorithm \u0026#34;SHA256WITHRSA\u0026#34; \\ --validity Value=20,Type=\u0026#34;DAYS\u0026#34; Lưu lại CertificateArn từ kết quả đầu ra, sau đó lấy chứng chỉ về:\naws acm-pca get-certificate \\ --certificate-authority-arn \u0026lt;specify_arn_of_PrivateCA\u0026gt; \\ --certificate-arn \u0026lt;specify_arn_of_Certificate_generated_above\u0026gt; \\ --output text \u0026gt; certificate.pem 3. Chạy báo cáo kiểm tra theo yêu cầu Bạn có thể đợi lịch trình Cron chạy hoặc kích hoạt thủ công để kiểm tra ngay lập tức.\nCách 1: Chỉnh sửa EventBridge Rule Vào console EventBridge -\u0026gt; Rules -\u0026gt; Chọn PCAReportRule -\u0026gt; Edit -\u0026gt; Chuyển lịch trình sang chạy mỗi 30 phút để test -\u0026gt; Sau đó hoàn nguyên lại.\nHình 3: Chỉnh sửa lịch trình của PCAReportRule để kiểm tra\nCách 2: Kích hoạt từ Lambda Console Vào console Lambda -\u0026gt; Chọn hàm PCAauditReportLambdaGenerator -\u0026gt; Tab Test -\u0026gt; Nhấn nút Test.\nHình 4: Sử dụng console để kích hoạt kiểm tra\n4. Xác minh kết quả Kiểm tra S3 Bucket: Báo cáo kiểm tra sẽ được tạo trong thư mục audit-report của bucket bạn đã chỉ định.\nHình 5: Báo cáo kiểm tra được lưu vào S3 bucket được chỉ định\nKiểm tra Security Hub: Vì chứng chỉ thử nghiệm hết hạn trong 20 ngày (dưới ngưỡng 30 ngày), Security Hub sẽ hiển thị Findings.\nHình 6: Xem các phát hiện báo cáo kiểm tra trong Security Hub\nKiểm tra Email (SNS): Bạn sẽ nhận được email cảnh báo chi tiết về chứng chỉ sắp hết hạn.\nHình 7: Email thông báo mẫu được gửi bởi Amazon SNS\nKết luận Giải pháp này biến đổi việc quản lý chứng chỉ truyền thống từ một quy trình thủ công, dễ xảy ra lỗi thành một quy trình tự động. Bằng cách triển khai mẫu CloudFormation này, bạn có thể:\nTự động hóa việc tạo và xử lý các báo cáo kiểm tra AWS Private CA. Nhận thông báo tức thì khi chứng chỉ sắp hết hạn. Duy trì khả năng hiển thị tập trung thông qua Security Hub. Giảm thiểu rủi ro gián đoạn dịch vụ do chứng chỉ hết hạn. Hệ thống có khả năng mở rộng này giúp đơn giản hóa việc quản lý chứng chỉ và tăng cường tư thế bảo mật tổng thể của tổ chức bạn.\n"},{"uri":"https://quangbom16.github.io/full-workshop/5-workshop/5.3-infrastructure-setup/5.3.1-deploy/","title":"Deploy Infrastructure","tags":[],"description":"","content":"Source: https://github.com/Aohk22/fcj-1-file-analyzer/tree/main\nDeployment Steps Run the Terraform workflow and Image Builder pipeline in order:\nterraform init terraform fmt terraform validate Create the Image Builder resources:\n./plan_imagebuilder.sh terraform apply plan.tfplan Script source:\n#!/usr/bin/env sh terraform plan -out=img_builder.tfplan \\ -target=aws_imagebuilder_infrastructure_configuration.imgbuilder_infra_config \\ -target=module.image_builder_pipeline_fhandle \\ -target=module.image_builder_pipeline_fquery \\ -target=module.instance_profile_imgbuilder \\ -target=aws_internet_gateway.igw_main \\ -target=aws_route_table.route_table_public \\ -target=aws_route_table_association.rt_associate_sn_pub_1 \\ -target=aws_iam_role_policy_attachment.imgbuilder_ec2_profile \\ -target=aws_iam_role_policy_attachment.imgbuilder_ec2_ecr_profile \\ -target=aws_iam_role_policy_attachment.imgbuilder_ssm_core Build the AMIs:\n./start_image_pipeline.sh # wait until AMI build completes Script source, it polls the AWS api for status:\n#!/usr/bin/env bash arn_build_versions=() arn_pipelines=( \u0026#34;arn:aws:imagebuilder:ap-southeast-2:005716755011:image-pipeline/fhandle-img-pipeline\u0026#34; \u0026#34;arn:aws:imagebuilder:ap-southeast-2:005716755011:image-pipeline/fquery-img-pipeline\u0026#34; ) echo \u0026#34;Sending pipeline requests.\u0026#34; for arn in \u0026#34;${arn_pipelines[@]}\u0026#34;; do result=$( aws imagebuilder start-image-pipeline-execution \\ --image-pipeline-arn \u0026#34;${arn}\u0026#34; ) arn_build_versions+=(\u0026#34;$(echo \u0026#34;${result}\u0026#34; | jq -r \u0026#39;.imageBuildVersionArn\u0026#39;)\u0026#34;) done for arn in \u0026#34;${arn_build_versions[@]}\u0026#34;; do echo \u0026#34;$arn\u0026#34; done # wait for image. for build_version in \u0026#34;${arn_build_versions[@]}\u0026#34;; do echo \u0026#34;Polling ${build_version}...\u0026#34; prev_status=\u0026#34;_none\u0026#34; while status=\u0026#34;$(aws imagebuilder get-image --image-build-version-arn \u0026#34;$build_version\u0026#34; | jq -r \u0026#39;.image.state.status\u0026#39;)\u0026#34; if [[ \u0026#34;$prev_status\u0026#34; != \u0026#34;${status}\u0026#34; ]]; then echo \u0026#34;Status: ${status}\u0026#34; prev_status=\u0026#34;${status}\u0026#34; fi sleep 5 [[ \u0026#34;$status\u0026#34; != \u0026#34;AVAILABLE\u0026#34; ]] do true; done done echo \u0026#34;Image build complete.\u0026#34; Deploy the full infrastructure:\nterraform plan -out=plan.tfplan terraform apply plan.tfplan "},{"uri":"https://quangbom16.github.io/full-workshop/5-workshop/5.1-workshop-overview/","title":"Workshop Overview","tags":[],"description":"","content":"Workshop: Deploy File Analyzer Infrastructure with Terraform Introduction In this hands-on workshop, you will deploy a complete file analyzer application infrastructure on AWS using Terraform. The infrastructure includes auto-scaling groups, load balancers, VPC endpoints, and S3 integration - all provisioned as Infrastructure as Code.\nArchitecture Overview The infrastructure consists of:\nVPC with public and private subnets across 2 availability zones Application Load Balancer (ALB) for traffic distribution 2 Auto Scaling Groups: Public ASG: Frontend/web tier Private ASG: Backend/processing tier S3 Gateway Endpoint for secure S3 access Security Groups for network isolation IAM Roles for EC2 permissions What You\u0026rsquo;ll Learn Initialize and configure Terraform for AWS Deploy multi-tier infrastructure using Terraform modules Configure auto-scaling groups and load balancers Set up VPC endpoints for secure AWS service access Verify and test deployed infrastructure Clean up resources efficiently Time Required Estimated Duration: 20 minutes\nWorkshop Flow Prerequisites (2 minutes) - Setup tools and credentials Infrastructure Setup (10 minutes) - Configure and deploy Verification (5 minutes) - Test the application Cleanup (3 minutes) - Remove all resources "},{"uri":"https://quangbom16.github.io/full-workshop/4-eventparticipated/4.2-event2/","title":"Event 2: DevOps on AWS Workshop","tags":[],"description":"","content":"Summary Report: \u0026ldquo;DevOps on AWS Workshop\u0026rdquo; Event Objectives Instill the DevOps culture and mindset, focusing on key performance metrics (DORA). Master the AWS Developer Tools suite to build fully automated CI/CD pipelines. Understand Infrastructure as Code (IaC) using CloudFormation and AWS CDK. Explore containerization strategies on AWS (ECS, EKS, App Runner). Implement comprehensive monitoring and observability using CloudWatch and X-Ray. Speakers AWS DevOps Specialists \u0026amp; Community Leaders Key Highlights DevOps Mindset \u0026amp; Culture Cultural Shift: Moving from siloed development and operations to a unified culture. Metrics that Matter: Deep dive into DORA metrics (Deployment Frequency, Lead Time for Changes, Time to Restore Service, Change Failure Rate) to measure success. AWS DevOps Services – CI/CD Pipeline Source \u0026amp; Build\nAWS CodeCommit: Managing secure Git repositories and comparing GitFlow vs. Trunk-based development strategies. AWS CodeBuild: configuring build environments and integrating automated testing. Deployment \u0026amp; Orchestration\nDeployment Strategies: Detailed breakdown of Blue/Green (zero downtime), Canary (risk mitigation), and Rolling updates using AWS CodeDeploy. AWS CodePipeline: Orchestrating the entire release process from commit to production. Infrastructure as Code (IaC) CloudFormation: Defining infrastructure using JSON/YAML templates and managing drift detection. AWS CDK: The power of defining infrastructure using familiar programming languages (TypeScript, Python) and using constructs for reusable patterns. Comparison: Discussion on when to use declarative templates (CFN) versus imperative code (CDK). Container Services on AWS Registry: Securing images with Amazon ECR and lifecycle policies. Orchestration Choices: Amazon ECS: For deep AWS integration and simplicity. Amazon EKS: For Kubernetes-native workloads and portability. AWS App Runner: For rapid deployment of containerized web apps without managing infrastructure. Monitoring \u0026amp; Observability Full-Stack Visibility: Moving beyond simple metrics to distributed tracing with AWS X-Ray. CloudWatch: Setting up composite alarms and dashboards to proactively manage system health. Key Takeaways Automation is Everything Pipeline First: Every project should start with a pipeline. Manual deployments are a risk. Immutable Infrastructure: Servers should not be patched in place; they should be replaced via automated deployments. The Power of IaC Version Control Infrastructure: Treating infrastructure definitions exactly like application code allows for rollbacks, reviews, and consistency across environments. CDK Efficiency: Using AWS CDK significantly speeds up development by reducing boilerplate code compared to raw CloudFormation. Operational Excellence Observability: It’s not just about knowing if the system is down, but why. Distributed tracing is essential for microservices. Deployment Safety: Always use deployment strategies like Canary or Blue/Green to minimize blast radius during updates. Applying to Work Audit Current Pipelines: Review existing CI/CD processes and implement DORA metrics tracking. Adopt IaC: Begin migrating manually created resources to AWS CDK or CloudFormation stacks. Containerize Legacy Apps: Evaluate monolithic applications for migration to Amazon ECS or App Runner. Enhance Monitoring: Implement AWS X-Ray for critical microservices to identify performance bottlenecks. Event Experience The \u0026ldquo;DevOps on AWS Workshop\u0026rdquo; was an intensive, full-day deep dive that connected the dots between theoretical DevOps principles and practical AWS implementation.\nThe morning session on CI/CD cleared up the specific use cases for each AWS Code* service. The demo of a full pipeline showed how seamless the integration is. The IaC discussion was a highlight. Seeing the code reduction when switching from CloudFormation templates to AWS CDK constructs was convincing evidence to adopt CDK for future projects. The afternoon session on containers provided a clear decision matrix for choosing between ECS, EKS, and App Runner, which is often a confusing topic. The Observability segment emphasized that monitoring is a proactive engineering discipline, not just a reactive support task. Overall, this workshop provided the technical toolkit necessary to accelerate software delivery while maintaining stability and security on the AWS cloud.\n"},{"uri":"https://quangbom16.github.io/full-workshop/3-blogstranslated/3.2-blog2/","title":"Thông báo thế hệ thứ hai của AWS Outposts racks với hiệu suất và khả năng mở rộng đột phá tại cơ sở","tags":[],"description":"","content":"Bởi Micah Walter\nBài viết gốc: Announcing second-generation AWS Outposts racks with breakthrough performance and scalability on-premises - AWS News Blog doc: GG docs Hôm nay, chúng tôi công bố sự ra mắt rộng rãi của thế hệ thứ hai AWS Outposts racks, đánh dấu sự đổi mới mới nhất từ AWS cho edge computing. Thế hệ mới này bao gồm hỗ trợ cho các instance Amazon Elastic Compute Cloud (Amazon EC2) chạy x86 mới nhất, khả năng mở rộng và cấu hình mạng đơn giản hóa mới, cùng với các instance networking được tăng tốc được thiết kế đặc biệt cho các workload có độ trễ cực thấp và thông lượng cao. Những cải tiến này mang lại hiệu suất cao hơn cho nhiều loại workload tại chỗ, chẳng hạn như các hệ thống giao dịch cốt lõi của dịch vụ tài chính và các workload 5G Core của viễn thông.\nCác khách hàng như athenahealth, FanDuel, First Abu Dhabi Bank, Mercado Libre, Liberty Latin America, Riot Games, Vector Limited và Wiwynn đã và đang sử dụng Outposts racks cho các workload cần duy trì tại chỗ. Outposts rack thế hệ thứ hai có thể cung cấp độ trễ thấp, xử lý dữ liệu cục bộ hoặc đáp ứng nhu cầu về data residency, chẳng hạn như game servers cho các trò chơi trực tuyến nhiều người chơi, dữ liệu giao dịch của khách hàng, hồ sơ y tế, hệ thống điều khiển công nghiệp và sản xuất, Business Support Systems (BSS) của viễn thông và edge inference của nhiều mô hình machine learning (ML). Giờ đây, khách hàng có thể tận dụng thế hệ bộ xử lý mới nhất và các cấu hình Outposts racks tiên tiến hơn để hỗ trợ xử lý nhanh hơn, dung lượng bộ nhớ cao hơn và băng thông mạng tăng lên.\nCác instance EC2 thế hệ mới nhất Chúng tôi rất vui mừng thông báo hỗ trợ cục bộ cho thế hệ mới nhất (thế hệ thứ 7) của các instance Amazon EC2 chạy x86 trên AWS Outposts racks, bắt đầu với các instance C7i compute-optimized, các instance M7i general-purpose và các instance R7i memory-optimized. Các instance mới này cung cấp gấp đôi vCPU, memory và network bandwidth trong khi mang lại hiệu suất tốt hơn tới 40% so với các instance C5, M5 và R5 trên Outposts racks thế hệ trước.\nChúng được cung cấp sức mạnh bởi bộ xử lý Intel Xeon Scalable thế hệ thứ 4 và lý tưởng cho nhiều loại workload tại chỗ yêu cầu hiệu suất nâng cao như các database lớn hơn, các ứng dụng tiêu tốn nhiều memory hơn, phân tích big data thời gian thực nâng cao, mã hóa và streaming video hiệu suất cao, và edge inference dựa trên CPU với các mô hình ML phức tạp hơn. Hỗ trợ cho nhiều instance EC2 thế hệ mới nhất, bao gồm các instance hỗ trợ GPU, sẽ sớm ra mắt.\nVideo này sẽ giải thích những tiến bộ lớn trong AWS Outposts racks mới.\nVideo này sẽ giải thích những tiến bộ lớn trong AWS Outposts racks mới: Next-gen AWS Outposts racks: Built for tomorrow’s on-premises demands | Amazon Web Services Đơn giản hoá khả năng mở rộng và cấu hình mạng Chúng tôi đã hoàn toàn tái thiết kế networking trong thế hệ Outposts mới nhất của mình, làm cho nó đơn giản và có khả năng mở rộng hơn bao giờ hết. Trọng tâm của bản nâng cấp này là Outposts network rack mới của chúng tôi, hoạt động như một trung tâm cho tất cả lưu lượng compute và storage của bạn.\nThiết kế mới này mang lại ba lợi ích chính:\nGiờ đây bạn có thể mở rộng tài nguyên compute của mình độc lập với cơ sở hạ tầng networking, mang lại cho bạn sự linh hoạt và hiệu quả chi phí hơn khi các workload của bạn phát triển. Chúng tôi đã tích hợp khả năng phục hồi mạng ngay từ đầu, với network rack tự động xử lý các lỗi thiết bị để giữ cho hệ thống của bạn hoạt động trơn tru. Việc kết nối với môi trường tại chỗ và AWS Regions giờ đây trở nên dễ dàng – bạn có thể cấu hình mọi thứ từ địa chỉ IP đến cài đặt VLAN và BGP thông qua các API đơn giản hoặc giao diện console được cập nhật của chúng tôi. Các instance Amazon EC2 chuyên biệt với accelerated networking Chúng tôi đang giới thiệu một danh mục mới các instance Amazon EC2 chuyên biệt trên Outposts racks với accelerated networking. Các instance này được xây dựng có mục đích cho các workload mission-critical nhạy cảm nhất về độ trễ, chuyên sâu về compute và thông lượng cao nhất tại chỗ. Để mang lại hiệu suất tốt nhất có thể, ngoài Outpost logical network, các instance này còn có một secondary physical network với network accelerator cards được kết nối với top-of-rack (TOR) switches.\nĐầu tiên trong danh mục này là các instance bmn-sf2e, được thiết kế cho độ trễ cực thấp với hiệu suất deterministic. Các instance mới chạy trên bộ xử lý Sapphire Rapids mới nhất của Intel (Xeon Scalable thế hệ thứ 4), mang lại hiệu suất duy trì 3.9 GHz trên tất cả các core với phân bổ memory hào phóng – 8GB RAM cho mỗi CPU core. Chúng tôi đã trang bị các instance bmn-sf2e với card mạng AMD Solarflare X2522 kết nối trực tiếp với top-of-rack switches.\nĐối với khách hàng dịch vụ tài chính, đặc biệt là các công ty thị trường vốn, các instance này cung cấp networking deterministic thông qua Layer 2 (L2) multicast gốc, precision time protocol (PTP) và độ dài cáp bằng nhau. Điều này cho phép khách hàng đáp ứng các yêu cầu quy định về giao dịch công bằng và tiếp cận bình đẳng trong khi dễ dàng kết nối với cơ sở hạ tầng giao dịch hiện có của họ.\nInstance Name vCPUs Memory (DDR5) Network Bandwidth NVMe SSD Storage Accelerated Network Cards Accelerated Bandwidth (Gbps) bmn-sf2e.metal-16xl 64 512 GiB 25 Gbps 2 x 8 TB (16 TB) 2 100 bmn-sf2e.metal-32xl 128 1024 GiB 50 Gbps 4 x 8 TB (32 TB) 4 200 Loại instance thứ hai, bmn-cx2, được tối ưu hóa cho thông lượng cao và độ trễ thấp. Instance này có NVIDIA ConnectX-7 400G NIC được kết nối vật lý với top-of-rack switches tốc độ cao, mang lại băng thông mạng bare metal lên tới 800 Gbps hoạt động ở gần line rate. Với Layer 2 (L2) multicast gốc và hỗ trợ PTP phần cứng, instance này lý tưởng cho các workload thông lượng cao như phân phối dữ liệu thị trường thời gian thực, phân tích rủi ro và các ứng dụng mạng 5G core của viễn thông.\nInstance Name vCPUs Memory (DDR5) Network Bandwidth NVMe SSD Storage Accelerated Network Cards Accelerated Bandwidth (Gbps) bmn-cx2.metal-48xl 192 1024 GiB 50 Gbps 4 x 4 TB (16 TB) 2 800 Hình 2: Các instance chuyên biệt\nTóm lại, thế hệ Outposts racks mới mang lại hiệu suất, khả năng mở rộng và khả năng phục hồi nâng cao cho nhiều loại workload tại chỗ, ngay cả đối với các workload mission-critical với các yêu cầu nghiêm ngặt nhất về độ trễ và thông lượng. Bạn có thể lựa chọn và bắt đầu đặt hàng từ AWS Management Console. Các instance mới duy trì tính nhất quán với các triển khai khu vực bằng cách hỗ trợ cùng các API, AWS Management Console, automation, governance policies và security controls trên cloud và tại chỗ, cải thiện năng suất của nhà phát triển và hiệu quả CNTT.\nNhững điều cần biết Khi ra mắt, Outposts racks thế hệ thứ hai có thể được vận chuyển đến Mỹ và Canada và được kết nối trở lại 6 AWS Regions bao gồm US East (N. Virginia và Ohio), US West (Oregon), EU West (London và France) và Asia Pacific (Singapore). Hỗ trợ cho nhiều quốc gia và vùng lãnh thổ cũng như AWS Regions sẽ sớm ra mắt. Khi ra mắt, Outposts racks thế hệ thứ hai hỗ trợ cục bộ một tập hợp con các dịch vụ AWS có trong Outposts racks thế hệ trước. Hỗ trợ cho nhiều loại instance EC2 và nhiều dịch vụ AWS sẽ sớm ra mắt.\nĐể tìm hiểu thêm, hãy truy cập trang sản phẩm AWS Outposts racks và hướng dẫn sử dụng. Bạn cũng có thể nói chuyện với chuyên gia Outposts nếu bạn sẵn sàng thảo luận về nhu cầu tại cơ sở của mình.\n1/5/2025: Dung lượng Memory (DDR5) được cập nhật trong bảng cho instance 48xl.\n"},{"uri":"https://quangbom16.github.io/full-workshop/2-proposal/","title":"Proposal","tags":[],"description":"","content":" Proposal document (.docx) Multi-Platform File Analysis System - VirusTotal Clone 1. Project Summary This project aims to develop and deploy a multi-platform file analysis system, operating similarly to VirusTotal. The system will allow users to upload suspicious files for scanning and analysis by multiple antivirus engines and various other analysis services. The primary goal is to provide a powerful, user-friendly tool for detecting and assessing potential file-based threats, thereby enhancing cybersecurity.\nThe system will be entirely built and deployed on the Amazon Web Services (AWS) cloud platform, leveraging AWS\u0026rsquo;s leading managed services, scalability, and security features to ensure high performance, reliability, and availability.\n2. Problem Statement The Challenge In an increasingly sophisticated and prevalent cybersecurity threat landscape, the demand for effective file analysis tools is paramount. VirusTotal has proven its value as a critical community service, helping users and cybersecurity professionals quickly identify malicious files. This project is initiated with the desire to create a similar, customizable, and extensible solution, serving research, educational, or specific application purposes.\nThe Solution This platform provides a centralized web interface where users can:\nUpload suspicious files (executables, scripts, office documents). Submit domains, IP addresses, or URLs for analysis. Automatically scan data with multiple antivirus engines, sandbox environments, and OSINT sources. Correlate results with threat intelligence feeds to improve detection accuracy. Share anonymized reports with the research community to foster collaboration. Analysis requests are processed in two different ways:\nFast Query (Query Service):\nIf the file/URL has already been analyzed, the Web Server sends its hash to the Query Service. The Query Service checks DynamoDB for existing results. If found, results are instantly returned to the user via the web interface. New Processing (Processing Service):\nIf the data is not yet available, the system forwards the raw file/URL to the Processing Service. The Processing Service performs in-depth analysis, scanning, and report generation. Results are sent back to the Web Server for user delivery and simultaneously stored in DynamoDB for future queries. This hybrid approach reduces response times for repeated requests while ensuring scalability for new analyses.\nObjectives Develop Core Functionality: Build a user interface (UI) that allows file uploads, a query service to check for existing analysis results, and a processing service to perform new file analyses. Multi-Engine Integration: Enable integration with various scanning and analysis tools (e.g., APIs of antivirus engines, static/dynamic analysis sandboxes). AWS Deployment: Design and deploy the system architecture on AWS to ensure high availability, flexible scalability, and robust security. Cost Optimization: Build a cost-effective architecture, leveraging appropriate AWS services for the project\u0026rsquo;s scale. Establish CI/CD Pipeline: Set up a Continuous Integration/Continuous Delivery (CI/CD) pipeline to automate application development and deployment. 3. Solution Architecture Summary User sends analysis request for file. Web Server sends request to Query Service. (Query using file hash) Query Service communicates with Database. Database responds to Query Service. Query Service responds to Web Server. If query successful send HTML response to User. If not then send file to Processing Service. (Web Server should hold raw file data) Processing Service sends report back to Web Server. Also stores report in Database. Database syncs. Diagram for AWS Web App Layer (UI):\nUsers access the system through the ALB, which distributes requests to EC2 instances in the Auto Scaling Group. This layer handles the interface and request intake.\nServices Layer:\nIncludes the Query Service and Processing Service, both deployed in Auto Scaling Groups within private subnets.\nQuery Service: Connects to DynamoDB to handle hash-based queries. Processing Service: Receives raw data, performs malware analysis, generates reports, and stores results in DynamoDB. Data Layer:\nAmazon DynamoDB stores two categories of data:\nView: Analysis results ready for user consumption. Event Store: Logs and raw data for deeper investigations. Scalability:\nBoth the Web App and Services layers use Auto Scaling Groups to ensure the system can handle high request volumes without compromising performance.\nAWS Services Used The system leverages the following key AWS services:\nAmazon VPC (Virtual Private Cloud): Creates an isolated virtual network, divided into multiple subnets (10.0.100.0/24, 10.0.101.0/24, 10.0.102.0/24, 10.0.103.0/24) across Availability Zones for high availability. Elastic Load Balancer (ALB): Distributes incoming traffic to Web App (UI) instances running on EC2. Amazon EC2: Hosts the Web App and backend services. Auto Scaling Group: Dynamically scales the number of EC2 instances to maintain performance and cost efficiency. Amazon DynamoDB: A NoSQL database that stores analysis reports, query results, and service synchronization data. 5. Roadmap \u0026amp; Development Milestones Project Plan: During internship (Months 1–3): 3 months in total. Month 1: Research AWS and upgrade hardware. Month 2: Design and refine the system architecture. Month 3: Deploy, test, and launch the system. 6. Budget Estimation Infrastructure Costs AWS Services: EC2 instances:\t6 × t4g.nano (6 × 0.0042 × 720h): $18.14 EBS\t6 × 20 GB = 120 GB × $0.10/GB:\t$12.00 Load Balancer (ALB)\t1 ALB, light traffic:\t$15.00 NAT instance\t1 × t4g.nano (replacement NAT Gateway):\t$3.02 DynamoDB\t10 GB, small on-demand:\t$5.00 Data transfer OUT\t100 GB × $0.09/GB:\t$9.00 CloudWatch \u0026amp; misc\tLogs + basicmetrics:\t$3.00 Total\t≈ $69.14 / month\n7. Risk Assessment Risk Matrix Malware Infection: High impact, low probability. API Rate Limiting: High impact, medium probability. Cost Overruns: Medium impact, low probability. Mitigation Strategies Malware: Strict network isolation (Private Subnets) and non-execution policies. API: Caching analysis results in DynamoDB to minimize external calls. Cost: AWS Budget alerts and Auto Scaling limits. Contingency Plans Switch to \u0026ldquo;Cached Only\u0026rdquo; mode if external APIs fail. Rapid infrastructure teardown via Terraform if costs spike. 8. Expected Outcomes Technical Improvements Automated scanning workflow replaces manual checks. High availability achieved through AWS Auto Scaling. Long-term Value Centralized threat database for instant hash lookups. Reusable Terraform modules for future cloud projects. "},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Secure the AWS Root Account using Multi-Factor Authentication (MFA). Apply Identity and Access Management (IAM) best practices (Groups, Users, Policies). Configure Account settings and understand AWS Support plans. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Account Security: - Review AWS Account settings - Setup Multi-Factor Authentication (MFA) for Root User - Practice: + Enable Virtual MFA device for Root Account 09/15/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn about IAM (Identity and Access Management) - Create Admin Group and Admin User - Practice: + Create \u0026ldquo;Administrators\u0026rdquo; Group + Create IAM User and add to Group 09/15/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ 4 - Account Authentication Support: + Set IAM Password Policy + Create Account Alias (Custom Login URL) - Verify login with new IAM Admin User 09/15/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ 5 - Explore and Configure AWS Management Console: + Customize Dashboard widgets + Set up Billing Alerts/Budgets + Understand Regions and Availability Zones settings 09/15/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ 6 - AWS Support: + Understand Support Plans (Basic, Developer, Business, Enterprise) + How to create Support Cases - Practice: + Simulate opening a support case 09/15/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ Week 2 Achievements: Successfully secured the AWS Root User by activating Multi-Factor Authentication (MFA).\nImplemented IAM best practices:\nCreated a dedicated Admin Group with AdministratorAccess policy. Created an individual IAM User for daily tasks to avoid using the Root account. Configured a custom Password Policy and Account Alias for easier login. Configured the AWS Management Console environment and set up Budgets/Billing Alarms to monitor costs.\nUnderstood the different AWS Support tiers and learned the procedure to open and manage support cases for technical or billing issues.\n"},{"uri":"https://quangbom16.github.io/full-workshop/5-workshop/5.3-infrastructure-setup/5.3.2-checking/","title":"Checking using AWS console","tags":[],"description":"","content":"Checking If Terraform Created Infrastructure Correctly VPC and routes Image builder pipelines EC2 status Load balancer rules Target group health "},{"uri":"https://quangbom16.github.io/full-workshop/5-workshop/5.2-prerequiste/","title":"Prerequisites","tags":[],"description":"","content":"Prerequisites Before starting this workshop, ensure you have the following ready:\n1. AWS Account Active AWS account with administrator access Recommended: Use a sandbox/development account Ensure you\u0026rsquo;re in the Asia Pacific (Singapore) ap-southeast-1 region 2. Required Tools Terraform (version \u0026gt;= 1.0)\n# Check installation terraform version # Download from: https://www.terraform.io/downloads AWS CLI (version \u0026gt;= 2.0)\n# Check installation aws --version # Configure credentials aws configure Git\n# Clone the project git clone https://github.com/Aohk22/fcj-1-file-analyzer.git cd fcj-1-file-analyzer/terraform/envs/dev 3. AWS Credentials Configure your AWS credentials:\naws configure # AWS Access Key ID: [Your Access Key] # AWS Secret Access Key: [Your Secret Key] # Default region: ap-southeast-1 # Default output format: json Or set environment variables:\nexport AWS_ACCESS_KEY_ID=\u0026#34;your-access-key\u0026#34; export AWS_SECRET_ACCESS_KEY=\u0026#34;your-secret-key\u0026#34; export AWS_DEFAULT_REGION=\u0026#34;ap-southeast-1\u0026#34; 4. Required IAM Permissions Your AWS user/role needs permissions for:\nEC2 (create instances, security groups, launch templates) Auto Scaling (create ASGs, launch configurations) ELB (create ALB, target groups, listeners) VPC (create subnets, route tables, endpoints) IAM (create roles, policies) 5. Cost Considerations Estimated cost: ~$5-10 for 20 minutes\nEC2 instances: t3.micro (included in free tier if eligible) ALB: ~$0.025/hour Data transfer: minimal Tip: Ensure you complete the cleanup section to avoid unexpected charges!\n6. Verify Setup Run these commands to verify your setup:\n# Check Terraform terraform version # Check AWS credentials aws sts get-caller-identity # Check region aws configure get region "},{"uri":"https://quangbom16.github.io/full-workshop/4-eventparticipated/4.3-event3/","title":"Event 3: AWS Well-Architected Security Pillar Workshop","tags":[],"description":"","content":"Summary Report: \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; Event Objectives Deep dive into the Security Pillar of the AWS Well-Architected Framework. Understand the core security principles: Least Privilege, Zero Trust, and Defense in Depth. Analyze the top cloud security threats specifically within the Vietnamese market. Master the 5 key security domains: IAM, Detection, Infrastructure Protection, Data Protection, and Incident Response. Learn practical automation for security using Lambda and Step Functions. Speakers AWS Security Solutions Architects Key Highlights Opening \u0026amp; Security Foundation Core Principles: Re-emphasizing Least Privilege, Zero Trust, and Defense in Depth as the non-negotiable foundations of any cloud architecture. Shared Responsibility Model: Clarifying the boundary between AWS\u0026rsquo;s security of the cloud and the customer\u0026rsquo;s security in the cloud. Local Context: Discussion on the top cybersecurity threats facing Vietnamese enterprises today. Pillar 1: Identity \u0026amp; Access Management (IAM) Modern Architecture: Moving away from long-term IAM User credentials towards temporary credentials and IAM Identity Center (SSO). Control Mechanisms: Using Service Control Policies (SCPs) for multi-account governance and setting permission boundaries. Mini Demo: Validating IAM Policies and simulating access to ensure least privilege is actually enforced. Pillar 2: Detection Continuous Monitoring: Enabling CloudTrail at the organization level and centralizing findings with AWS Security Hub and Amazon GuardDuty. Logging Strategy: Importance of capturing logs at every layer (VPC Flow Logs, ALB, S3). Detection-as-Code: Automating alerting using Amazon EventBridge to react to security events in real-time. Pillar 3: Infrastructure Protection Network Security: Implementing strict VPC segmentation and understanding the correct placement of public vs. private resources. Defense Layers: The correct model for applying Security Groups (stateful) vs. NACLs (stateless), and layering AWS WAF and Shield for edge protection. Pillar 4: Data Protection Encryption Strategy: Comprehensive use of AWS KMS for key management, rotation, and enforcing encryption at-rest (EBS, S3, RDS) and in-transit. Secrets Management: Patterns for rotating database credentials using AWS Secrets Manager to eliminate hardcoded secrets in code. Pillar 5: Incident Response (IR) IR Lifecycle: Preparation, Detection, Containment, Eradication, Recovery, and Post-Incident Activity. Playbooks: Walkthrough of specific scenarios: Handling a compromised IAM Access Key. Reacting to accidental S3 public exposure. Isolating EC2 instances infected with malware. Automation: Using Lambda and Step Functions to auto-remediate simple threats. Key Takeaways Zero Trust is a Journey Identity is the new perimeter: In the cloud, network perimeters are porous; identity controls (IAM) are the primary defense. Eliminate long-term keys: Static access keys are the #1 vector for account compromise. Defense in Depth Layered Security: Never rely on a single control. Use WAF at the edge, Security Groups at the instance, and Encryption at the data layer. Encryption is standard: Encryption should be the default state for all data, not an optional feature. Automate Response Speed matters: In a security incident, manual response is too slow. Automated playbooks (e.g., auto-revoking a compromised key) save the day. Practice IR: You cannot figure out your Incident Response plan during an actual attack. Game days are essential. Applying to Work Audit IAM: Immediately review and remove unused IAM users/keys and enable MFA for everyone. Enable GuardDuty: Turn on GuardDuty in all regions to detect anomalous behavior. Review Secrets: Migrate hardcoded API keys/passwords from code to AWS Secrets Manager. Define Playbooks: Write down the exact steps the team must take if an S3 bucket is found public or a server is compromised. Event Experience The \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; workshop was a dense, high-impact session that highlighted the critical importance of security in every stage of the cloud journey.\nThe \u0026ldquo;Vietnam Threat Landscape\u0026rdquo; segment was particularly eye-opening, showing that local businesses are often targeted due to misconfigured S3 buckets and exposed IAM keys. The IAM Mini Demo provided a practical way to verify permissions, which I can immediately apply to my current project to tighten security. The Incident Response section was the most valuable, as it moved beyond theory into actionable playbooks. Learning how to automate the isolation of a compromised EC2 instance using Lambda was a highlight. Overall, the session reinforced that security is not just the job of the security team, but a fundamental responsibility of every cloud builder.\n"},{"uri":"https://quangbom16.github.io/full-workshop/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"Blog 1 - Automating AWS Private CA audit reports and certificate expiration alerts This blog guides you through building an automated workflow to monitor and alert on the expiration of digital certificates issued by AWS Private CA. The solution leverages a combination of EventBridge, Lambda, S3, SNS, and Security Hub to generate daily audit reports. This allows administrators to proactively identify expiring certificates (including those created via API that are not automatically tracked by ACM), ensuring security compliance and preventing service disruptions.\nBlog 2 - Announcing second-generation AWS Outposts racks with breakthrough performance This article announces the launch of the second-generation AWS Outposts racks, delivering breakthrough performance and scalability for on-premises environments. Key highlights include support for 7th generation EC2 instances (C7i, M7i, R7i) offering up to 40% better performance, a redesigned network architecture for simplified scaling, and the introduction of specialized instances designed for ultra-low latency and high throughput workloads (such as financial trading or 5G core networks).\nBlog 3 - AWS Lambda standardizes billing for INIT Phase This blog announces a significant change in AWS pricing: Effective August 1, 2025, the initialization phase (INIT phase/cold start) will be billed for all Lambda function configurations. The content explains the Lambda execution lifecycle in detail, guides how to use CloudWatch to monitor INIT duration, and suggests cost optimization strategies such as using Lambda SnapStart or Provisioned Concurrency to minimize the impact of this change.\n"},{"uri":"https://quangbom16.github.io/full-workshop/3-blogstranslated/3.3-blog3/","title":"AWS Lambda chuẩn hóa việc tính phí cho giai đoạn INIT","tags":[],"description":"","content":"Bởi Shubham Gupta và Jeff Gebhart\nBài viết gốc: AWS Lambda standardizes billing for INIT Phase - AWS Compute Blog doc: GG docs Có hiệu lực từ ngày 1 tháng 8 năm 2025, AWS sẽ chuẩn hóa việc tính phí cho giai đoạn khởi tạo (INIT) trên tất cả các cấu hình hàm AWS Lambda. Thay đổi này đặc biệt ảnh hưởng đến các lệnh gọi theo yêu cầu của các hàm Lambda được đóng gói dưới dạng tệp ZIP sử dụng các runtime được quản lý, mà trước đây thời lượng giai đoạn INIT không được tính phí.\nBản cập nhật này chuẩn hóa việc tính phí giai đoạn INIT trên tất cả các loại runtime, gói triển khai và chế độ gọi. Hầu hết người dùng sẽ thấy tác động tối thiểu đến tổng hóa đơn Lambda của họ từ thay đổi này, vì giai đoạn INIT thường chỉ xảy ra trong một phần rất nhỏ các lệnh gọi hàm.\nTrong bài đăng này, chúng tôi thảo luận về Vòng đời hàm Lambda và những thay đổi sắp tới đối với việc tính phí giai đoạn INIT. Bạn sẽ tìm hiểu điều gì xảy ra trong giai đoạn INIT và khi nào nó xảy ra, cách giám sát thời lượng giai đoạn INIT của bạn và các chiến lược để tối ưu hóa giai đoạn này và giảm thiểu chi phí.\nTìm hiểu vòng đời thực thi hàm Lambda Vòng đời thực thi hàm Lambda bao gồm ba giai đoạn riêng biệt: INIT, INVOKE và SHUTDOWN.\nGiai đoạn INIT được kích hoạt trong quá trình \u0026ldquo;khởi động lạnh\u0026rdquo; khi Lambda tạo một môi trường thực thi mới cho một hàm để phản hồi một lệnh gọi. Tiếp theo là giai đoạn INVOKE nơi yêu cầu được xử lý. Cuối cùng là giai đoạn SHUTDOWN nơi môi trường thực thi bị chấm dứt. Trong giai đoạn INIT, Lambda thực hiện một loạt các bước chuẩn bị trong thời gian tối đa 10 giây. Dịch vụ truy xuất mã hàm từ một S3 bucket nội bộ của Amazon, hoặc từ Amazon Elastic Container Registry (Amazon ECR) đối với các hàm sử dụng đóng gói container. Sau đó, nó cấu hình một môi trường với bộ nhớ, runtime và các cài đặt khác được chỉ định.\nKhi môi trường thực thi được chuẩn bị, Lambda thực hiện bốn tác vụ chính theo trình tự:\nKhởi tạo bất kỳ tiện ích mở rộng nào được cấu hình (Extension INIT) Khởi động runtime (Runtime INIT) Thực thi mã tĩnh của hàm (Function INIT) Chạy bất kỳ hook runtime trước checkpoint nào (chỉ áp dụng cho Lambda SnapStart) Hình 1: Vòng đời thực thi hàm Lambda\nTìm hiểu những thay đổi về tính phí Phí Lambda được tính dựa trên số lượng yêu cầu và thời lượng cần thiết để mã chạy. Thời lượng được tính từ thời điểm mã hàm bắt đầu chạy cho đến khi hoàn thành hoặc chấm dứt, được làm tròn lên đến mili giây gần nhất. Chi phí thời lượng phụ thuộc vào lượng bộ nhớ bạn cấp phát cho hàm của mình.\nTrước đây, thời lượng giai đoạn INIT không được bao gồm trong Billed Duration đối với các hàm sử dụng runtime được quản lý với đóng gói lưu trữ ZIP, như được chứng minh trong nhật ký Amazon CloudWatch:\nREPORT RequestId: xxxxx Duration: 250.06 ms Billed Duration: 251 ms Memory Size: 1024 MB Max Memory Used: 350 MB Init Duration: 100.77 ms Tuy nhiên, các hàm được cấu hình với runtime tùy chỉnh, Provisioned Concurrency (PC) hoặc đóng gói OCI đã bao gồm thời lượng giai đoạn INIT trong Billed Duration của chúng.\nCó hiệu lực từ ngày 1 tháng 8 năm 2025, giai đoạn INIT sẽ được tính phí trên tất cả các loại cấu hình và thời lượng giai đoạn INIT cũng sẽ được bao gồm trong Billed Duration đối với các lệnh gọi theo yêu cầu của các hàm sử dụng runtime được quản lý với đóng gói lưu trữ ZIP. Sau thay đổi này, dòng nhật ký REPORT Request ID sẽ hiển thị như sau:\nREPORT RequestId: xxxxx Duration: 250.06 ms Billed Duration: 351 ms Memory Size: 1024 MB Max Memory Used: 350 MB Init Duration: 100.77 ms Các khoản phí thời lượng giai đoạn INIT tiếp theo sẽ tuân theo giá thời lượng theo yêu cầu tiêu chuẩn dành riêng cho từng Vùng AWS, có thể tìm thấy trên trang giá Lambda. Đối với các hàm AWS Lambda@Edge, thời lượng giai đoạn INIT sẽ được tính phí theo tỷ lệ thời lượng Lambda@Edge.\nTìm thời lượng giai đoạn INIT và tác động đến việc tính phí Lambda Bạn đã có thể giám sát thời gian dành cho giai đoạn INIT của các lệnh gọi hàm của mình thông qua dòng nhật ký \u0026ldquo;REPORT RequestId\u0026rdquo; trong CloudWatch Logs, bao gồm giá trị \u0026ldquo;Init Duration\u0026rdquo;. Ngoài ra, nếu Lambda Insights được bật, bạn có thể sử dụng chỉ số CloudWatch \u0026ldquo;init_duration\u0026rdquo;.\nĐể phân tích toàn diện hơn, bạn có thể sử dụng truy vấn CloudWatch Log Insights sau để tạo báo cáo chi tiết ước tính thời lượng giai đoạn INIT trước đây không được tính phí:\nfilter @type = \u0026#34;REPORT\u0026#34; | stats sum((@memorySize/1000000/1024) * (@billedDuration/1000)) as BilledGBs, sum((@memorySize/1000000/1024) * ((@duration + @initDuration - @billedDuration)/1000)) as UnbilledInitGBs, UnbilledInitGBs / (UnbilledInitGBs + BilledGBs) as UnbilledInitRatio Truy vấn CloudWatch Log Insights cung cấp ba chỉ số thiết yếu:\nBilledGBs: Đại diện cho tổng GB-s (gigabyte-giây) hiện đang được tính phí cho các nhóm nhật ký đã chọn. UnbilledInitGBs: Hiển thị tổng GB-s tiêu thụ trong giai đoạn INIT mà trước đây không được bao gồm trong tính phí. Ratio: Cho biết tỷ lệ phần trăm tổng GB-s được gán cho thời lượng giai đoạn INIT trước đây không được tính phí. Hình 2: Báo cáo CloudWatch Log Insights\nSử dụng các khả năng giám sát hiện có này cho phép bạn chủ động đánh giá và tối ưu hóa thời gian INIT của hàm Lambda, có khả năng giảm thiểu tác động của cấu trúc thanh toán mới đến tổng chi phí của bạn.\nTìm hiểu và tối ưu hóa giai đoạn INIT của Lambda Giai đoạn INIT của Lambda được kích hoạt trong hai trường hợp cụ thể: trong quá trình tạo môi trường thực thi mới và khi một hàm mở rộng quy mô để đáp ứng nhu cầu. Mã INIT này chỉ chạy trong các \u0026ldquo;khởi động lạnh\u0026rdquo; này và bị bỏ qua trong các lệnh gọi tiếp theo sử dụng các môi trường ấm hiện có.\nCác nhà phát triển có thể sử dụng giai đoạn INIT để tạo, khởi tạo và cấu hình các đối tượng dự kiến được sử dụng lại trên nhiều lệnh gọi trong quá trình INIT hàm thay vì thực hiện nó trong trình xử lý. Khởi tạo các phụ thuộc/đối tượng được chia sẻ trước sẽ giảm độ trễ của các lệnh gọi tiếp theo. Ví dụ:\nTải xuống thêm thư viện hoặc phụ thuộc. Thiết lập kết nối máy khách với các dịch vụ AWS khác như Amazon S3 hoặc Amazon DynamoDB. Tạo kết nối cơ sở dữ liệu để chia sẻ trên các lệnh gọi. Truy xuất các tham số ứng dụng hoặc bí mật từ Amazon Systems Manager Parameter Store hoặc AWS Secrets Manager. Khi phát triển các hàm Lambda, điều quan trọng là phải quyết định một cách chiến lược mã nào chạy trong giai đoạn INIT so với giai đoạn xử lý, vì nó ảnh hưởng đến cả hiệu suất và chi phí.\nTối ưu hóa kích thước gói/thư viện Ba yếu tố chính ảnh hưởng đến hiệu suất của giai đoạn INIT:\nKích thước của gói hàm, về các thư viện và phụ thuộc được nhập, và các lớp Lambda. Lượng mã và công việc INIT. Hiệu suất của các thư viện và các dịch vụ khác trong việc thiết lập kết nối và các tài nguyên khác. Các gói hàm lớn hơn làm tăng thời gian tải xuống mã. Bạn có thể giảm thời lượng giai đoạn INIT bằng cách giảm kích thước gói, dẫn đến khởi động lạnh nhanh hơn và chi phí INIT thấp hơn. Các công cụ như esbuild có thể tối ưu hóa hiệu suất hơn nữa bằng cách thu nhỏ và đóng gói các gói.\nTối ưu hóa việc thực thi giai đoạn INIT và hiệu quả chi phí Tần suất thực thi giai đoạn INIT (hoặc khởi động lạnh) tác động trực tiếp đến cả hiệu suất và hiệu quả chi phí. Theo phân tích các khối lượng công việc Lambda trong sản xuất, INIT (khởi động lạnh) thường xảy ra dưới 1% các lệnh gọi.\nBạn có thể sử dụng giai đoạn INIT để thực hiện các thao tác một lần có lợi cho các lệnh gọi tiếp theo, ví dụ như tải dữ liệu tĩnh từ Amazon S3 hoặc DynamoDB trong quá trình INIT.\nLambda SnapStart Lambda SnapStart cung cấp một giải pháp hiệu quả để giảm độ trễ khởi động lạnh và chi phí giai đoạn INIT. Khi được bật, SnapStart tạo một ảnh chụp nhanh trong quá trình INIT hàm đầu tiên và sử dụng lại nó cho các khởi động lạnh tiếp theo, loại bỏ nhu cầu thực thi giai đoạn INIT lặp lại. SnapStart được hỗ trợ cho các runtime Java, .NET và Python.\nProvisioned Concurrency Provisioned Concurrency là một tính năng của Lambda giúp khởi tạo trước môi trường thực thi trước khi bất kỳ lệnh gọi nào xảy ra. Phương pháp chủ động này loại bỏ hiệu quả tác động hiệu suất của giai đoạn INIT đối với các lệnh gọi hàm riêng lẻ. Từ góc độ tối ưu hóa chi phí, Provisioned Concurrency phù hợp nhất cho các khối lượng công việc có mẫu sử dụng bền vững trên 60%.\nKết luận Có hiệu lực từ ngày 1 tháng 8 năm 2025, AWS đang chuẩn hóa việc tính phí giai đoạn INIT cho AWS Lambda. AWS cung cấp nhiều cách để bạn tối ưu hóa cả hiệu suất và chi phí của các hàm Lambda của mình. Cho dù bạn đang sử dụng SnapStart, triển khai Provisioned Concurrency hay tối ưu hóa mã INIT, chúng tôi khuyên bạn nên làm việc chặt chẽ với các nhóm hỗ trợ của AWS để xác định phương pháp tối ưu hóa phù hợp nhất cho các yêu cầu khối lượng công việc cụ thể của bạn.\n"},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Master the core components of Amazon VPC (Virtual Private Cloud). Implement network security using Security Groups and Network ACLs. Deploy EC2 instances within a custom network architecture. Understand Hybrid Connectivity via Site-to-Site VPN. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Introduction to VPC Networking: - Understand CIDR blocks - 1.1 Subnets: Public vs. Private - 1.2 Route Tables: Associations and Route propagation - 1.3 Internet Gateway (IGW): Enabling internet access 09/22/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ 3 - Advanced Networking \u0026amp; Firewall: - 1.4 NAT Gateway: Outbound internet for private subnets - 2. Firewall in VPC: + Security Groups (Stateful) + Network ACLs (Stateless) 09/22/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ 4 - 3. Preparation Steps: Planning VPC design (IP addressing) - 4. Deploying Amazon EC2 Instances: + Create a custom VPC + Launch EC2 in Public Subnet + Launch EC2 in Private Subnet 09/22/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ 5 - 5. Setting Up Site-to-Site VPN Connection: - Understand Virtual Private Gateway (VGW) \u0026amp; Customer Gateway (CGW) - Learn VPN configuration steps - Practice: Configure the AWS side of a VPN connection 09/22/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ 6 - Review \u0026amp; Troubleshooting: - Test connectivity between instances (Ping, SSH) - Verify Security Group rules - Troubleshoot common VPC connection issues 09/22/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ Week 3 Achievements: Designed and created a custom Virtual Private Cloud (VPC) with proper CIDR block planning.\nSuccessfully configured network components:\nPublic and Private Subnets. Route Tables for traffic direction. Internet Gateway for public access and NAT Gateway for private subnet updates. Secured the network layers by implementing Security Groups (Instance level) and Network ACLs (Subnet level).\nDeployed EC2 instances into the custom network and verified internal/external connectivity.\nGained theoretical and practical knowledge on establishing a Site-to-Site VPN connection between AWS and on-premises environments.\n"},{"uri":"https://quangbom16.github.io/full-workshop/5-workshop/5.3-infrastructure-setup/5.3.3-application-demonstration/","title":"Application demonstration","tags":[],"description":"","content":"Access application through load balancer Output after selecting a file and query Content is also stored to local storage Recovering the analysis of a file using hash "},{"uri":"https://quangbom16.github.io/full-workshop/5-workshop/5.3-infrastructure-setup/","title":"Infrastructure Setup","tags":[],"description":"","content":"Infrastructure Setup In this section, you will configure and deploy the complete file analyzer infrastructure using Terraform. The process involves configuring variables, initializing Terraform, and deploying all AWS resources.\nWhat Will Be Created This Terraform configuration will provision:\nNetwork Infrastructure:\nVPC with custom CIDR block 2 Public subnets across availability zones 2 Private subnets across availability zones Internet Gateway and NAT Gateway Route tables and associations DNS configuration Compute Resources:\nApplication Load Balancer (ALB) with target groups Public Auto Scaling Group (min: 1, max: 3) Private Auto Scaling Group (min: 1, max: 3) Launch templates with user data scripts Health checks and scaling policies Supporting Services:\nDynamoDB table for application state Security groups for ALB, public ASG, and private ASG IAM roles and instance profiles for EC2 SSH key pair for instance access CI/CD Pipeline (Image Builder):\nEC2 Image Builder pipeline Custom AMI creation with application dependencies Automated image refresh workflow Terraform Module Structure The infrastructure is organized into modular components:\nnetworking.tf - VPC, subnets, gateways, routes security_groups.tf - Firewall rules for each tier services_load_balancer.tf - ALB configuration services_groups.tf - Auto Scaling Groups launch_template.tf - EC2 launch configurations dynamodb.tf - DynamoDB table setup image_builder.tf - AMI pipeline configuration dns.tf - DNS and routing configuration Estimated Time ⏱️ 10 minutes\nSteps Overview Configure Variables - Set AWS region, instance types, and capacity Initialize Terraform - Download AWS provider and validate configuration Deploy Infrastructure - Create all resources with single command 💡 All resources will be tagged with Environment: dev and ManagedBy: terraform for easy identification and cost tracking.\n⚠️ Note: The Image Builder pipeline may take additional time to create custom AMIs. The initial deployment will use the base AMI specified in variables.\nLet\u0026rsquo;s proceed with the configuration!\n"},{"uri":"https://quangbom16.github.io/full-workshop/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"Event 1: AI/ML/GenAI on AWS Workshop Date: Saturday, November 15, 2025 Time: 8:30 AM – 12:00 PM Location: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City Hosted by: Kha Van Agenda includes:\nWelcome \u0026amp; Introduction (8:30 – 9:00 AM): Overview of AI/ML landscape in Vietnam. AWS AI/ML Services Overview (9:00 – 10:30 AM): Deep dive into Amazon SageMaker, data preparation, and MLOps. Live Demo: SageMaker Studio walkthrough. Generative AI with Amazon Bedrock (10:45 AM – 12:00 PM): Foundation Models, Prompt Engineering, RAG, and Agents. Event 2: DevOps on AWS Workshop Date: Monday, November 17, 2025 Time: 8:30 AM – 5:00 PM Location: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City Hosted by: Kha Van Morning Session Agenda (8:30 AM – 12:00 PM):\nWelcome \u0026amp; DevOps Mindset (8:30 – 9:00 AM): DevOps culture, principles, and DORA metrics. AWS DevOps Services – CI/CD Pipeline (9:00 – 10:30 AM): Source Control: AWS CodeCommit \u0026amp; Git strategies. Build \u0026amp; Test: CodeBuild configuration. Deployment: CodeDeploy strategies (Blue/Green, Canary). Orchestration: CodePipeline automation. Infrastructure as Code (10:45 AM – 12:00 PM): CloudFormation \u0026amp; AWS CDK. Afternoon Session Agenda (1:00 PM – 5:00 PM):\nContainer Services: Docker, ECR, ECS, EKS, and App Runner. Monitoring \u0026amp; Observability: CloudWatch and X-Ray. Event 3: AWS Well-Architected Security Pillar Workshop Date: Saturday, November 29, 2025 Time: 8:30 AM – 12:00 PM (Morning Only) Location: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City Hosted by: Kha Van Agenda:\nOpening \u0026amp; Security Foundation (8:30 – 8:50 AM): Core principles (Least Privilege, Zero Trust) \u0026amp; Shared Responsibility Model. Pillar 1 — Identity \u0026amp; Access Management (8:50 – 9:30 AM): Modern IAM Architecture, SSO, and MFA. Pillar 2 — Detection (9:30 – 9:55 AM): Continuous Monitoring with CloudTrail, GuardDuty, and Security Hub. Pillar 3 — Infrastructure Protection (10:10 – 10:40 AM): Network Security (VPC, WAF) \u0026amp; Workload protection. Pillar 4 — Data Protection (10:40 – 11:10 AM): Encryption (KMS), Keys \u0026amp; Secrets Manager. Pillar 5 — Incident Response (11:10 – 11:40 AM): IR Playbooks \u0026amp; Automation using Lambda. Wrap-Up \u0026amp; Q\u0026amp;A (11:40 – 12:00 PM): Roadmap for security learning. "},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Define a Capstone/Practice Project idea. Understand the fundamental architecture of Web Applications (Frontend, Backend, Database). Select appropriate AWS services for the proposed project. Design the initial architectural diagram. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - 1. Project Ideation: - Brainstorm project ideas (e.g., Static website, 3-tier web app, Serverless API) - 4. How a website works: + DNS, IP, HTTP/HTTPS, Request/Response cycle 09/29/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ 3 - 2. Service Selection \u0026amp; Research: - Analyze requirements (Traffic, Storage, Compute needs) - Compare services (e.g., EC2 vs. Lambda, RDS vs. DynamoDB, S3 for static content) 09/29/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ 4 - 5. Backend Research: - Understand the role of Backend (Business Logic, APIs) - Research connection between Web Server and Database - Explore Load Balancing and Auto Scaling concepts 09/29/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ 5 - 3. Project Architecture Design: - Draft the initial diagram + Define Public/Private subnets + Place components (Web Tier, App Tier, DB Tier) - Tool: Draw.io / Lucidchart 09/29/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ 6 - Review \u0026amp; Finalize Proposal: - Review the diagram against AWS Well-Architected pillars (Security, Reliability) - Finalize the list of services to be used 09/29/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ Week 4 Achievements: Successfully defined the project scope and main idea.\nGained a solid understanding of how web applications operate, including the flow from the user\u0026rsquo;s browser to the backend server.\nResearched and selected the most suitable AWS services for the project (balancing cost and performance).\nCompleted the preliminary Architectural Diagram (Draft 1), clearly visualizing the interaction between components such as VPC, EC2/Lambda, Database, and Load Balancers.\n"},{"uri":"https://quangbom16.github.io/full-workshop/5-workshop/5.4-clean-up/","title":"Clean up","tags":[],"description":"","content":"Run terraform destroy to clean up "},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Stay updated with AWS latest announcements by translating technical blogs. Improve diagramming skills and finalize the Project Architecture using Draw.io. Deep dive into Module 3: Advanced EC2 configuration and operations. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - 1. Blog Translation: - Translate: \u0026ldquo;Announcing second-generation AWS Outposts racks with breakthrough performance and scalability on-premises\u0026rdquo; - Translate: \u0026ldquo;AWS Lambda standardizes billing for INIT Phase\u0026rdquo; 10/06/2025 10/10/2025 https://aws.amazon.com/blogs/ 3 - 1. Blog Translation (Cont.): - Translate: \u0026ldquo;Automating AWS Private CA audit reports and certificate expiration alerts\u0026rdquo; - 2. Diagramming Skills: - Watch tutorial: \u0026ldquo;Diagrams for AWS Architecture\u0026rdquo; 10/06/2025 10/10/2025 YouTube Link 4 - 3. Project Architecture Design: - Apply best practices from the tutorial - Design the detailed project architecture using Draw.io - Review and refine the diagram components 10/06/2025 10/10/2025 https://app.diagrams.net/ 5 - 4. Study Module 3 (Part 1): - EC2 Configuration details: + User Data \u0026amp; Metadata + Storage options (EBS types, Instance Store) + Network Interfaces (ENI) 10/06/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - 5. Study Module 3 (Part 2): - EC2 Operations: + Monitoring with CloudWatch + Systems Manager (SSM) basics + Image creation and management (AMI) 10/06/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ Week 5 Achievements: Gained deep insights into new AWS features by translating 3 major technical blog posts regarding Outposts, Lambda billing, and Private CA.\nLearned professional architectural diagramming techniques via video tutorials.\nCompleted the detailed Architectural Diagram for the capstone project using Draw.io.\nMastered detailed EC2 concepts in Module 3, specifically focusing on advanced configuration (User Data, ENI) and operational best practices.\n"},{"uri":"https://quangbom16.github.io/full-workshop/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Deploying To AWS Cloud Using Terraform Overview This lab provides a guided, hands-on introduction to provisioning cloud infrastructure on Amazon Web Services (AWS) using Terraform. Participants learn how to define infrastructure as code, manage configuration state, and execute automated workflows to create, update, and destroy cloud resources in a controlled and repeatable way.\nContent Workshop overview Prerequiste Initialize the infrastructure How to destroy initialized infrastructure "},{"uri":"https://quangbom16.github.io/full-workshop/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"During my internship at AWS First Cloud Journey from 09/08/2025 to 12/09/2025, I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI participated in designing and deploying a Malware Analysis System on AWS, through which I improved my skills in programming, software architecture, AWS services, CI/CD tools, and teamwork.\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ☐ ✅ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ☐ ✅ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ☐ ✅ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ✅ ☐ ☐ 7 Communication Presenting ideas and reporting work clearly ✅ ☐ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ☐ ✅ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ☐ ✅ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ☐ ✅ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Based on the evaluation above, I have identified key areas for personal development:\nStrengthen self-discipline: Strictly comply with organizational rules, regulations, and time management. Improve learning agility: Enhance the ability to absorb new technical knowledge and concepts more rapidly. Enhance problem-solving thinking: Develop a more structured and creative approach to identifying and resolving technical issues. Develop collaboration skills: Continue to improve communication effectiveness and teamwork interaction. "},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Establish team collaboration protocols and Development Workflow (Git/GitHub). Develop backend query services for data retrieval. Finalize project documentation and publish the Proposal via GitHub Pages. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Team Meeting \u0026amp; Setup: - Assign specific tasks to team members - Agree on communication channels and meeting schedule - Define GitHub Workflow (Branching strategy, PR process) 10/13/2025 10/17/2025 Project Management Tool / GitHub 3 - Documentation Finalization: - Review and finalize the content of the Project Proposal - Format the Proposal for web publication 10/13/2025 10/17/2025 Project Proposal Draft 4 - GitHub Pages Configuration: - Initialize the repository for the documentation site - Configure GitHub Pages to host the Proposal - Push the finalized content to the site 10/13/2025 10/17/2025 https://pages.github.com/ 5 - Backend Development (Part 1): - Design the structure for Query Services - Implement basic query logic (e.g., retrieving status, querying hash existence) 10/13/2025 10/17/2025 Backend Architecture Diagram 6 - Backend Development (Part 2): - Continue writing Query Services - Commit code to GitHub following the agreed workflow (Pull Requests/Code Review) 10/13/2025 10/17/2025 https://cloudjourney.awsstudygroup.com/ Week 6 Achievements: Successfully organized the team structure, assigned tasks, and unified the coding workflow using GitHub (Commits, PRs).\nCompleted the development of the core Backend Query Services, allowing the system to handle data retrieval requests.\nFinalized the detailed Project Proposal.\nSuccessfully configured and deployed the Project Documentation website using GitHub Pages.\n"},{"uri":"https://quangbom16.github.io/full-workshop/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment\nThe working environment at the AWS Vietnam office is professional and well-organized. The workspace provides all necessary equipment and infrastructure for technical work. Team members maintain a collaborative atmosphere that supports learning and problem-solving. The office layout also facilitates both focused individual work and team collaboration when needed.\n2. Support from Mentor / Team Admin\nThe mentor provided technical guidance on AWS services, cloud architecture, and DevOps practices. Questions were addressed with clear explanations and relevant documentation. The mentor encouraged hands-on learning through practical tasks and real-world scenarios. Support from mentors via the WhatsApp group ensured that members always had smooth access to necessary resources and tools throughout the internship period.\n3. Relevance of Work to Academic Major\nThe internship tasks were highly relevant to the curriculum of my Information Security and Computer Science major. Working with AWS infrastructure, Terraform, and CI/CD pipelines allowed me to directly apply theoretical knowledge of cloud computing, system architecture, and software development. This experience bridged the gap between academic learning and practice in a real-world environment.\n4. Learning \u0026amp; Skill Development Opportunities\nThe internship provided exposure to industry-standard tools and practices, including Terraform for Infrastructure as Code (IaC), AWS services (EC2, ALB, Auto Scaling, DynamoDB), DevOps workflows, and system architecture design. Participating in technical workshops on AI/ML, DevOps, and Security expanded my knowledge beyond the scope of the assigned project. These experiences developed both my technical competencies and professional working skills for the future.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive. Everyone operates with a spirit of sharing, ready to support and provide constructive feedback on new ideas. Team members collaborate effectively on projects and share expertise across different technical domains. The series of workshops and community events demonstrate AWS FCJ\u0026rsquo;s commitment to fostering a learning environment. Mutual respect and growing together were the highlights of my OJT period at AWS.\n6. Internship Policies / Benefits\nThe internship program provided hands-on tools to work with AWS infrastructure and apply them to real projects, which significantly enhanced my ability to absorb new knowledge. Access to AWS workshops, technical resources, and community events offered valuable knowledge and continuous learning opportunities.\n"},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Finalize and submit the Preliminary Project Proposal (including Sections 7 \u0026amp; 8). Perform detailed cost estimation (Pricing) for a monthly operation. Implement Query Services to establish communication between Frontend and Backend. Containerize the application using Docker and refine code logic. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2-3 - Documentation \u0026amp; Cost Estimation: - Complete Sections 7 and 8 of the Proposal - Calculate Monthly Pricing: Estimate costs for EC2, S3, DynamoDB, and Data Transfer - Submit the Preliminary Proposal 10/20/2025 10/21/2025 AWS Pricing Calculator / Proposal Draft 4-5 - Development \u0026amp; Containerization: - Write Query Services: Implement API calls to connect Frontend with Backend - Docker Configuration: Create Dockerfile and setup container environment for the app 10/22/2025 10/23/2025 Docker Docs / Project Source Code 6 - Refactoring \u0026amp; Debugging: - Fix File Paths: Adjust relative/absolute paths in the code for consistency - Review and correct Business Logic: Ensure data flows correctly through the new Query Services 10/24/2025 10/24/2025 https://cloudjourney.awsstudygroup.com/ Week 7 Achievements: Successfully updated the Proposal with completed Sections 7 \u0026amp; 8 and submitted the preliminary version.\nProduced a detailed Monthly Cost Estimation report for the project\u0026rsquo;s infrastructure.\nEstablished the connection between Frontend and Backend by implementing functional Query Services.\nContainerized the application by adding and configuring the Dockerfile.\nImproved code stability by fixing directory paths and refining the core processing logic.\n"},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Configure the local development environment for testing purposes. Refine the User Interface (UI) and restructure the Frontend codebase. Strengthen networking knowledge (CCNA) to support cloud configuration. Perform dry runs to verify application configuration and basic logic on the local machine. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Local Environment Configuration: - Install necessary libraries/dependencies - Configure environment variables (.env) - Setup run scripts to prepare for local testing 10/27/2025 10/31/2025 README / Install Guide 3 - Frontend Optimization: - Review the current UI and provide feedback - Refactor: Organize Frontend folder structure (CSS, JS, Assets) - Improve UX (Buttons, Forms, Status Display) 10/27/2025 10/31/2025 UI/UX Best Practices 4 - Study CCNA: - Study Networking fundamentals relevant to the project: + TCP/IP Model + IP Addressing \u0026amp; Subnetting + Common Ports (80, 443, 22) 10/27/2025 10/31/2025 CCNA Study Materials 5 - Test Run (Dry Run): - Execute the application start-up script - Verify that the application initializes without syntax errors or missing dependencies 10/27/2025 10/31/2025 Project Bug Tracker 6 - Basic Functional Check: - Check if the Frontend loads correctly on the local browser - Verify basic interactions (buttons, navigation) to ensure the configuration is valid 10/27/2025 10/31/2025 https://cloudjourney.awsstudygroup.com/ Week 8 Achievements: Successfully configured the local development environment with all necessary dependencies and environment variables.\nImproved the Frontend structure and User Interface based on team feedback.\nEnhanced understanding of networking core concepts (CCNA), aiding in future VPC/Security Group configurations.\nVerified the application configuration through local test runs, ensuring the code is ready for further development steps.\n"},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives: Verify and test the User Interface (UI) deployed on the AWS environment. Deep dive into AWS Database services (DynamoDB) and Content Delivery (CloudFront). Continue strengthening networking foundations through CCNA study. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Day Off (Personal Leave) 11/03/2025 11/03/2025 N/A 3 - UI Testing on AWS: - Access the deployed application URL - Verify UI responsiveness and functionality on the cloud environment - Report any visual bugs or latency issues 11/04/2025 11/07/2025 Project Deployment URL 4 - Study Amazon DynamoDB: - Understand NoSQL concepts - Learn about Tables, Items, Attributes, and Primary Keys - Lab: Create a simple DynamoDB table 11/04/2025 11/07/2025 https://000060.awsstudygroup.com/ 5 - Study Amazon CloudFront: - Understand Content Delivery Network (CDN) concepts - Learn about Distributions, Origins (S3/EC2), and Caching strategies - Lab: Configure CloudFront distribution 11/04/2025 11/07/2025 https://000094.awsstudygroup.com/ 6 - Study CCNA (Supplementary): - Review networking protocols (HTTP/HTTPS, DNS) - Understand how routing works in a larger network context 11/04/2025 11/07/2025 CCNA Study Materials Week 9 Achievements: Successfully tested the User Interface on the live AWS environment, ensuring the deployment was successful.\nGained practical knowledge of Amazon DynamoDB (NoSQL structure, Provisioned vs On-demand capacity).\nUnderstood how Amazon CloudFront works to accelerate content delivery and cache static assets.\nImproved networking knowledge (CCNA) to better understand data flow and connectivity in cloud architecture.\n"},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives: Implement core backend logic for malware detection (Hash comparison). Refine project documentation (Proposal). Introduction to AWS Observability using Amazon CloudWatch. Stay updated with AI/ML trends through AWS Community events. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Feature Implementation: - Develop function to read the malware hash database/file - Implement logic to compare User\u0026rsquo;s uploaded file hash against the known malware hash list 11/10/2025 11/14/2025 Project Documentation 3 - Documentation: - Review and adjust the Project Proposal to match the actual implementation progress - Update architectural changes if any 11/10/2025 11/14/2025 Project Proposal 4 - Day Off (Personal Leave) 11/10/2025 11/14/2025 N/A 5 - Study CloudWatch: - Follow the workshop: Introduction to Amazon CloudWatch - Learn about Metrics, Logs, and Dashboards 11/10/2025 11/14/2025 https://000008.awsstudygroup.com/ 6 - Testing \u0026amp; Automation: - Test the automatic hash update mechanism - Verify that new malware samples are correctly added to the comparison database 11/10/2025 11/14/2025 Project Source Code 7 - Event: AWS Cloud Mastery Series #1 - Topic: AI/ML/GenAI on AWS - Explore Generative AI services (Bedrock, Q) and Machine Learning workflows 11/15/2025 11/15/2025 AWS Community Events Week 10 Achievements: Successfully implemented the critical security feature: Comparing uploaded file hashes against a database of known malware hashes.\nUpdated the Project Proposal to align with the current technical direction.\nCompleted the introductory workshop on Amazon CloudWatch for system monitoring.\nVerified the automation script for fetching and updating malware hash samples.\nAttended AWS Cloud Mastery #1, gaining insights into the AI/ML and Generative AI ecosystem on AWS.\n"},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Objectives: Understand DevOps culture and master AWS CI/CD toolset through the Cloud Mastery workshop. Validate project functionality (Security/Malware analysis features). Reinforce networking fundamentals (CCNA) applied to Cloud. Learn about system monitoring and observability with Amazon CloudWatch. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Event: AWS Cloud Mastery Series #2 (DevOps) - Welcome \u0026amp; DevOps Mindset: Culture, DORA metrics, MTTR, deployment frequency - AWS DevOps Services: + Source: CodeCommit (GitFlow/Trunk-based) + Build: CodeBuild config + Deploy: CodeDeploy (Blue/Green, Canary) + Orchestration: CodePipeline - Demo: Full CI/CD Pipeline 11/17/2025 11/17/2025 AWS Community Events 3 - Project Testing: - Perform Unit Testing and Integration Testing - Focus: Verify the \u0026ldquo;Malware Hash Comparison\u0026rdquo; feature + Input sample hashes + Check against database/Threat Intelligence 11/17/2025 11/21/2025 Project Documentation 4 - Day Off (Personal Leave) 11/17/2025 11/21/2025 N/A 5 - Supplementary Study (Networking): - Study CCNA concepts relevant to Cloud: + Subnetting \u0026amp; Masks + VLANs vs VPC + Routing Protocols basics 11/17/2025 11/21/2025 CCNA Materials 6 - Monitoring \u0026amp; Observability: - Research Amazon CloudWatch: + Metrics \u0026amp; Namespaces + CloudWatch Logs (Log Groups/Streams) + Setting up Alarms 11/17/2025 11/21/2025 https://cloudjourney.awsstudygroup.com/ Week 11 Achievements: Attended AWS Cloud Mastery #2, gaining a solid grasp of DevOps principles (DORA metrics) and the complete CI/CD pipeline on AWS (CodeCommit, CodeBuild, CodeDeploy, CodePipeline).\nSuccessfully tested and verified the \u0026ldquo;Malware Hash Comparison\u0026rdquo; function of the project, ensuring accuracy in threat detection.\nStrengthened foundational networking knowledge (CCNA) to better understand VPC and connectivity.\nUnderstood how to monitor AWS resources and logs using Amazon CloudWatch.\n"},{"uri":"https://quangbom16.github.io/full-workshop/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12 Objectives: Finalize the Project Architecture Diagram with updated standards and components. Complete the comprehensive Project Proposal document (.docx). Update and refine the online Proposal Page. Prepare the Final Presentation Slide Deck. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Diagram Refinement: - Update architecture flow: + Add VPC Endpoint Gateway (S3/DynamoDB) for secure private access + Replace all icons with the latest AWS 2025 Architecture Icons 11/24/2025 11/28/2025 https://aws.amazon.com/architecture/icons/ 3 - Documentation (Part 1): - Finalize the Project Proposal document (.docx) - Ensure all sections are complete: + Executive Summary + Technical Architecture + Cost Estimation 11/24/2025 11/28/2025 https://cloudjourney.awsstudygroup.com/ 4 - Documentation (Part 2): - Edit and refine the Proposal Page (Wiki/Web version) - Synchronize content between the Word document and the online page for consistency 11/24/2025 11/28/2025 https://cloudjourney.awsstudygroup.com/ 5 - Presentation Preparation: - Create the Slide Deck for the final defense/presentation - Structure the slides: Problem -\u0026gt; Solution -\u0026gt; Architecture -\u0026gt; Demo -\u0026gt; Q\u0026amp;A 11/24/2025 11/28/2025 https://cloudjourney.awsstudygroup.com/ 6 - Final Review: - Polish the slides (Visuals, Animations) - Review all artifacts (Diagram, Doc, Slides) one last time before submission 11/24/2025 11/28/2025 https://cloudjourney.awsstudygroup.com/ Week 12 Achievements: Successfully updated the Architectural Diagram to meet the latest standards (AWS 2025 logos) and optimized security/flow with Endpoint Gateways.\nCompleted the full Project Proposal Document (.docx) detailing the entire solution.\nUpdated the Proposal Page to reflect the final status of the project.\nCreated a professional Slide Presentation ready for the final project reporting/defense.\n"},{"uri":"https://quangbom16.github.io/full-workshop/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://quangbom16.github.io/full-workshop/tags/","title":"Tags","tags":[],"description":"","content":""}]